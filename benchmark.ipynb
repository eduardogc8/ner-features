{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_utils as MLU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.models import Model, Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import TimeDistributed, Conv1D, Dense, Embedding\n",
    "from keras.layers import Dropout, LSTM, Bidirectional, MaxPooling1D\n",
    "from keras.layers import Input, concatenate, Concatenate, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import datetime\n",
    "import time\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ignore Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load PT Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pt_w2v_patch = 'C:\\word_embedding\\pt_cbow_s300.txt'\n",
    "pt_w2v = KeyedVectors.load_word2vec_format(pt_w2v_patch, unicode_errors=\"ignore\")\n",
    "pt_model_w2v = {w: vec for w, vec in zip(pt_w2v.index2word, pt_w2v.syn0)}\n",
    "del pt_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load EN Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "en_w2v_patch = 'C:\\word_embedding\\GoogleNews-vectors-negative300.bin'\n",
    "en_w2v = gensim.models.Word2Vec.load_word2vec_format(en_w2v_patch, binary=True)\n",
    "en_model_w2v = {w: vec for w, vec in zip(en_w2v.index2word, en_w2v.syn0)}\n",
    "del en_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Harem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('harem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('conll2003.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features dicitonary dic_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_feat = {}\n",
    "SIZE_PAD = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PT Word2vec Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_PAD = 20\n",
    "w2v_ = []\n",
    "sentence = []\n",
    "last_code = -1\n",
    "for word, code in zip(df['Word'], df['sentence_code']):\n",
    "    if last_code != code:\n",
    "        last_code = code\n",
    "        if len(sentence) > 0:\n",
    "            w2v_.append(np.array(sentence))\n",
    "        sentence = []\n",
    "    if str(word).lower() in pt_model_w2v:\n",
    "        sentence.append(pt_model_w2v[str(word).lower()])\n",
    "    else:\n",
    "        sentence.append(np.zeros(300, dtype=\"float32\"))\n",
    "if len(sentence) > 0:\n",
    "    w2v_.append(np.array(sentence))\n",
    "w2v_ = pad_sequences(w2v_, maxlen=SIZE_PAD, dtype='float32')\n",
    "dic_feat['w2v'] = w2v_\n",
    "del w2v_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4385, 20, 300)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_feat['w2v'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EN Word2Vec Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_ = []\n",
    "sentence = []\n",
    "last_code = -1\n",
    "for word, code in zip(df['Word'], df['sentence_code']):\n",
    "    if last_code != code:\n",
    "        last_code = code\n",
    "        if len(sentence) > 0:\n",
    "            w2v_.append(np.array(sentence))\n",
    "        sentence = []\n",
    "    if str(word).lower() in en_model_w2v:\n",
    "        sentence.append(en_model_w2v[str(word).lower()])\n",
    "    else:\n",
    "        sentence.append(np.zeros(300, dtype=\"float32\"))\n",
    "if len(sentence) > 0:\n",
    "    w2v_.append(np.array(sentence))\n",
    "w2v_ = pad_sequences(w2v_, maxlen=SIZE_PAD, dtype='float32')\n",
    "dic_feat['w2v'] = w2v_\n",
    "del w2v_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POS Feature (To-Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_, pos2idx = MLU.myHotEncode([[p] for p in df['Pos']])\n",
    "df['Pos'] = data_\n",
    "del data_\n",
    "\n",
    "\n",
    "pos_ = []\n",
    "sentence = []\n",
    "last_code = -1\n",
    "for pos, code in zip(df['Pos'], df['sentence_code']):\n",
    "    if last_code != code:\n",
    "        last_code = code\n",
    "        if len(sentence) > 0:\n",
    "            w2v_.append(np.array(sentence))\n",
    "        sentence = []\n",
    "    if str(word).lower() in en_model_w2v:\n",
    "        sentence.append(en_model_w2v[str(word).lower()])\n",
    "    else:\n",
    "        sentence.append(np.zeros(300, dtype=\"float32\"))\n",
    "if len(sentence) > 0:\n",
    "    w2v_.append(np.array(sentence))\n",
    "w2v_ = pad_sequences(w2v_, maxlen=SIZE_PAD, dtype='float32')\n",
    "dic_feat['w2v'] = w2v_\n",
    "del w2v_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphic Feature (To-Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_, graphic2idx = MLU.myHotEncode([[p] for p in df['Graphic']])\n",
    "df['Graphic'] = data_\n",
    "del data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BIO Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_classes = []\n",
    "for bio, classe in zip(df['bio'], df['class']):\n",
    "    if classe is None or type(classe) == float or classe.strip() == '':\n",
    "        bio_classes.append('O')\n",
    "    else:\n",
    "        bio_classes.append(classe + '-' + bio)\n",
    "data_, bio2idx = MLU.myHotEncode([[p] for p in bio_classes])\n",
    "bio_classes = data_\n",
    "del data_\n",
    "\n",
    "bio_ = []\n",
    "sentence = []\n",
    "last_code = -1\n",
    "for bio, code in zip(bio_classes, df['sentence_code']):\n",
    "    if last_code != code:\n",
    "        last_code = code\n",
    "        if len(sentence) > 0:\n",
    "            bio_.append(np.array(sentence))\n",
    "        sentence = []\n",
    "    sentence.append(bio)\n",
    "if len(sentence) > 0:\n",
    "    bio_.append(np.array(sentence))\n",
    "bio_ = pad_sequences(bio_, maxlen=SIZE_PAD, dtype='float32')\n",
    "dic_feat['bio'] = bio_\n",
    "del bio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BIOSE Class (To-Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "biose_classes = []\n",
    "for biose, classe in zip(df['biose'], df['class']):\n",
    "    if classe is None or type(classe) == float or classe.strip() == '':\n",
    "        biose_classes.append('O')\n",
    "    else:\n",
    "        biose_classes.append(classe + '-' + biose)\n",
    "data_, biose2idx = MLU.myHotEncode([[p] for p in biose_classes])\n",
    "df['biose_class'] = data_\n",
    "del biose_classes\n",
    "del data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_DIM = 300\n",
    "OUTPUT_DIM = 21\n",
    "def exemple_lstm_model():\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_dim=1000, name='LSTM0'))\n",
    "    model.add(Dense(256, activation='relu', name='Dence1'))\n",
    "    model.add(Dropout(0.5, name='Droupout2'))\n",
    "    model.add(Dense(7, activation='sigmoid', name='Dense_out3'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy')\n",
    "    \"\"\"\n",
    "    \n",
    "    input_w2v = Input(shape=(None, W2V_DIM), name='input_w2v')\n",
    "    w2v = LSTM(W2V_DIM, name='lstm_w2v', return_sequences=True)(input_w2v)\n",
    "    #w2v2 = LSTM(W2V_DIM, name='lstm_w2v2', return_sequences=True)(w2v)\n",
    "    \n",
    "    #output = concatenate([w2v], name='concat_inputs')\n",
    "    output = Dense(256, name='dense_concat')(w2v)\n",
    "    output = Dense(OUTPUT_DIM, activation='softmax', name='dense_output')(output)\n",
    "    model = Model(inputs=[input_w2v], outputs=[output])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam')\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "# ToDo (Felipe) - Diferentes funções que criam diferentes modelos que utilizam \n",
    "# features distintas, como CNN (morfológica), LSTM (Word2vec), LSTM (Graphics) ...\n",
    "# Criar os modelos baseados nos modelos do trabalho CNN+LSTN+Bidirecional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(run_id, model_create, dic_features, features, class_column, k=5, random_state=0, \n",
    "                  metric_average=\"macro\", epochs=10, verbose=1):\n",
    "    start_benchmark = time.time()\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    confusion = []\n",
    "    execution_time = []\n",
    "    test_time = []\n",
    "    \n",
    "    ss = ShuffleSplit(n_splits=k, random_state=0)\n",
    "    k_count = 0\n",
    "    for train_indexs, test_indexs in ss.split(dic_features[features[0]]):\n",
    "        k_count += 1\n",
    "        print(k_count, '/', k)\n",
    "        x_train = []\n",
    "        for feature in features:\n",
    "            x_train.append(dic_features[feature][train_indexs])\n",
    "        y_train = dic_features[class_column][train_indexs]\n",
    "        \n",
    "        x_test = []\n",
    "        for feature in features:\n",
    "            x_test.append(dic_features[feature][test_indexs])\n",
    "        y_test = dic_features[class_column][test_indexs]\n",
    "        \n",
    "        model = model_create()\n",
    "        start_time = time.time()\n",
    "        model_ = model.fit(x_train, y_train, verbose=verbose, epochs=epochs)\n",
    "        end_time = time.time() - start_time\n",
    "        execution_time.append(end_time)\n",
    "                \n",
    "        start_time = time.time()\n",
    "        result = model.predict(x_test)\n",
    "        end_time = time.time() - start_time\n",
    "        test_time.append(end_time)\n",
    "    \n",
    "        result = np.array([np.concatenate(t) for t in result]).round()\n",
    "        y_test = np.array([np.concatenate(t) for t in y_test])\n",
    "        \n",
    "        accuracy.append(accuracy_score(result, y_test))\n",
    "        precision.append(precision_score(result, y_test, average=metric_average))\n",
    "        recall.append(recall_score(result, y_test, average=metric_average))\n",
    "        f1.append(f1_score(result, y_test, average=metric_average))\n",
    "        confusion.append(confusion_matrix(result.argmax(axis=1), y_test.argmax(axis=1)))\n",
    "    \n",
    "    print('')\n",
    "    aux = time.time() - start_benchmark\n",
    "    print('Run time benchmark:', aux)\n",
    "    \n",
    "    results = {\n",
    "        'run_id': run_id,\n",
    "        'datetime': datetime.datetime.now(),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion': confusion,\n",
    "        'train_time': execution_time,\n",
    "        'test_time': test_time,\n",
    "        'benchmark_time': aux\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      "Epoch 1/10\n",
      "3946/3946 [==============================] - 7s 2ms/step - loss: 0.4870\n",
      "Epoch 2/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2800\n",
      "Epoch 3/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2298A:\n",
      "Epoch 4/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1903\n",
      "Epoch 5/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1510\n",
      "Epoch 6/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1180\n",
      "Epoch 7/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0885\n",
      "Epoch 8/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0658\n",
      "Epoch 9/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0525\n",
      "Epoch 10/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0377\n",
      "2 / 5\n",
      "Epoch 1/10\n",
      "3946/3946 [==============================] - 8s 2ms/step - loss: 0.4867A: 0s - loss: 0.\n",
      "Epoch 2/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2799\n",
      "Epoch 3/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2281A: 1s - loss: 0. - ETA: 0s - \n",
      "Epoch 4/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1870\n",
      "Epoch 5/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1495\n",
      "Epoch 6/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1152\n",
      "Epoch 7/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0904\n",
      "Epoch 8/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0654\n",
      "Epoch 9/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0480\n",
      "Epoch 10/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0353\n",
      "3 / 5\n",
      "Epoch 1/10\n",
      "3946/3946 [==============================] - 8s 2ms/step - loss: 0.4915\n",
      "Epoch 2/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2853\n",
      "Epoch 3/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2300\n",
      "Epoch 4/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1885\n",
      "Epoch 5/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1511\n",
      "Epoch 6/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1191\n",
      "Epoch 7/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0910A: 0s - lo\n",
      "Epoch 8/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0719\n",
      "Epoch 9/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0526\n",
      "Epoch 10/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0399\n",
      "4 / 5\n",
      "Epoch 1/10\n",
      "3946/3946 [==============================] - 8s 2ms/step - loss: 0.4893\n",
      "Epoch 2/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2813\n",
      "Epoch 3/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2294\n",
      "Epoch 4/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1875\n",
      "Epoch 5/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1511\n",
      "Epoch 6/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1190\n",
      "Epoch 7/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0918\n",
      "Epoch 8/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0692\n",
      "Epoch 9/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0511\n",
      "Epoch 10/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0421\n",
      "5 / 5\n",
      "Epoch 1/10\n",
      "3946/3946 [==============================] - 8s 2ms/step - loss: 0.4931\n",
      "Epoch 2/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2817\n",
      "Epoch 3/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.2284\n",
      "Epoch 4/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1895\n",
      "Epoch 5/10\n",
      "3946/3946 [==============================] - 5s 1ms/step - loss: 0.1542\n",
      "Epoch 6/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.1182\n",
      "Epoch 7/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0888\n",
      "Epoch 8/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0724\n",
      "Epoch 9/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0550\n",
      "Epoch 10/10\n",
      "3946/3946 [==============================] - 4s 1ms/step - loss: 0.0409\n",
      "\n",
      "Run time benchmark: 245.5698537826538\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "df_result = run_benchmark('example_run', exemple_lstm_model, dic_feat, ['w2v'], 'bio', epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>benchmark_time</th>\n",
       "      <th>confusion</th>\n",
       "      <th>datetime</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>run_id</th>\n",
       "      <th>test_time</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111617</td>\n",
       "      <td>245.569854</td>\n",
       "      <td>[[137, 3, 3, 1, 0, 3, 3, 0, 2, 1, 1, 2, 1, 2, ...</td>\n",
       "      <td>2019-02-13 14:31:20.248050</td>\n",
       "      <td>0.322739</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.369766</td>\n",
       "      <td>example_run</td>\n",
       "      <td>1.391279</td>\n",
       "      <td>46.006907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111617</td>\n",
       "      <td>245.569854</td>\n",
       "      <td>[[127, 6, 1, 0, 0, 5, 2, 0, 0, 0, 0, 0, 1, 2, ...</td>\n",
       "      <td>2019-02-13 14:31:20.248050</td>\n",
       "      <td>0.334770</td>\n",
       "      <td>0.335441</td>\n",
       "      <td>0.375181</td>\n",
       "      <td>example_run</td>\n",
       "      <td>1.415215</td>\n",
       "      <td>46.657130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102506</td>\n",
       "      <td>245.569854</td>\n",
       "      <td>[[120, 1, 2, 0, 1, 1, 1, 3, 1, 0, 1, 0, 2, 8, ...</td>\n",
       "      <td>2019-02-13 14:31:20.248050</td>\n",
       "      <td>0.303423</td>\n",
       "      <td>0.319078</td>\n",
       "      <td>0.334228</td>\n",
       "      <td>example_run</td>\n",
       "      <td>1.497045</td>\n",
       "      <td>47.407165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116173</td>\n",
       "      <td>245.569854</td>\n",
       "      <td>[[133, 3, 2, 2, 0, 3, 2, 0, 1, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>2019-02-13 14:31:20.248050</td>\n",
       "      <td>0.286153</td>\n",
       "      <td>0.294326</td>\n",
       "      <td>0.312007</td>\n",
       "      <td>example_run</td>\n",
       "      <td>1.711406</td>\n",
       "      <td>47.547488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097950</td>\n",
       "      <td>245.569854</td>\n",
       "      <td>[[119, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>2019-02-13 14:31:20.248050</td>\n",
       "      <td>0.352037</td>\n",
       "      <td>0.366727</td>\n",
       "      <td>0.381677</td>\n",
       "      <td>example_run</td>\n",
       "      <td>1.543870</td>\n",
       "      <td>47.669465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  benchmark_time  \\\n",
       "0  0.111617      245.569854   \n",
       "1  0.111617      245.569854   \n",
       "2  0.102506      245.569854   \n",
       "3  0.116173      245.569854   \n",
       "4  0.097950      245.569854   \n",
       "\n",
       "                                           confusion  \\\n",
       "0  [[137, 3, 3, 1, 0, 3, 3, 0, 2, 1, 1, 2, 1, 2, ...   \n",
       "1  [[127, 6, 1, 0, 0, 5, 2, 0, 0, 0, 0, 0, 1, 2, ...   \n",
       "2  [[120, 1, 2, 0, 1, 1, 1, 3, 1, 0, 1, 0, 2, 8, ...   \n",
       "3  [[133, 3, 2, 2, 0, 3, 2, 0, 1, 0, 0, 1, 1, 0, ...   \n",
       "4  [[119, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                    datetime        f1  precision    recall       run_id  \\\n",
       "0 2019-02-13 14:31:20.248050  0.322739   0.319500  0.369766  example_run   \n",
       "1 2019-02-13 14:31:20.248050  0.334770   0.335441  0.375181  example_run   \n",
       "2 2019-02-13 14:31:20.248050  0.303423   0.319078  0.334228  example_run   \n",
       "3 2019-02-13 14:31:20.248050  0.286153   0.294326  0.312007  example_run   \n",
       "4 2019-02-13 14:31:20.248050  0.352037   0.366727  0.381677  example_run   \n",
       "\n",
       "   test_time  train_time  \n",
       "0   1.391279   46.006907  \n",
       "1   1.415215   46.657130  \n",
       "2   1.497045   47.407165  \n",
       "3   1.711406   47.547488  \n",
       "4   1.543870   47.669465  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUIDADO PRA NÃO SALVAR EM CIMA DE UM ARQUIVO COM RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sempre muda o nome do arquivo pra não salvar em cima !\n",
    "df_result.to_csv('results/exemplo_DATA_E_HORA_AQUI.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
